user nginx;
worker_processes auto;
worker_rlimit_nofile 65535;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 4096;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';

    access_log /var/log/nginx/access.log main buffer=16k flush=2s;

    # Performance settings
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    keepalive_requests 100;
    
    # Compression
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml text/javascript 
               application/json application/javascript application/xml+rss 
               application/rss+xml application/atom+xml image/svg+xml;

    # Security headers
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Referrer-Policy "no-referrer-when-downgrade" always;
    add_header Content-Security-Policy "default-src 'self' http: https: data: blob: 'unsafe-inline'" always;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/s;
    limit_req_zone $binary_remote_addr zone=inference_limit:10m rate=50r/s;
    limit_req_status 429;

    # Connection limits
    limit_conn_zone $binary_remote_addr zone=addr:10m;
    limit_conn addr 100;

    # Upstream configuration for TorchServe
    upstream torchserve_inference {
        least_conn;
        
        # Health check
        # health_check interval=5s fails=3 passes=2;
        
        # TorchServe instances
        server torchserve-0.torchserve-headless.model-serving.svc.cluster.local:8080 max_fails=3 fail_timeout=30s;
        server torchserve-1.torchserve-headless.model-serving.svc.cluster.local:8080 max_fails=3 fail_timeout=30s;
        server torchserve-2.torchserve-headless.model-serving.svc.cluster.local:8080 max_fails=3 fail_timeout=30s;
        
        # Connection pooling
        keepalive 32;
        keepalive_requests 1000;
        keepalive_timeout 60s;
    }

    upstream torchserve_management {
        server torchserve.model-serving.svc.cluster.local:8081;
    }

    upstream torchserve_metrics {
        server torchserve.model-serving.svc.cluster.local:8082;
    }

    # Cache configuration
    proxy_cache_path /var/cache/nginx/models levels=1:2 keys_zone=model_cache:100m max_size=1g inactive=60m use_temp_path=off;

    # Main server block
    server {
        listen 80;
        listen [::]:80;
        server_name models.betterprompts.com;

        # Redirect to HTTPS
        return 301 https://$server_name$request_uri;
    }

    server {
        listen 443 ssl http2;
        listen [::]:443 ssl http2;
        server_name models.betterprompts.com;

        # SSL configuration
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers HIGH:!aNULL:!MD5;
        ssl_prefer_server_ciphers on;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;

        # OCSP stapling
        ssl_stapling on;
        ssl_stapling_verify on;
        ssl_trusted_certificate /etc/nginx/ssl/chain.pem;

        # Request body size limit
        client_max_body_size 50M;
        client_body_buffer_size 1M;

        # Timeouts
        proxy_connect_timeout 5s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;

        # Health check endpoint
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }

        # Model inference endpoint
        location /predictions/ {
            limit_req zone=inference_limit burst=20 nodelay;
            
            # CORS
            if ($request_method = 'OPTIONS') {
                add_header 'Access-Control-Allow-Origin' '*';
                add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';
                add_header 'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization';
                add_header 'Access-Control-Max-Age' 1728000;
                add_header 'Content-Type' 'text/plain; charset=utf-8';
                add_header 'Content-Length' 0;
                return 204;
            }

            # Proxy headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Buffering
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
            proxy_busy_buffers_size 8k;

            # Cache configuration for GET requests
            proxy_cache model_cache;
            proxy_cache_methods GET HEAD;
            proxy_cache_key "$scheme$request_method$host$request_uri$request_body";
            proxy_cache_valid 200 5m;
            proxy_cache_valid 404 1m;
            proxy_cache_use_stale error timeout invalid_header updating http_500 http_502 http_503 http_504;
            proxy_cache_lock on;
            proxy_cache_lock_timeout 5s;

            # Pass to upstream
            proxy_pass http://torchserve_inference;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
        }

        # Metrics endpoint (internal only)
        location /metrics {
            allow 10.0.0.0/8;
            allow 172.16.0.0/12;
            deny all;

            proxy_pass http://torchserve_metrics;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }

        # Model-specific endpoints with custom settings
        location ~ ^/predictions/intent_classifier {
            limit_req zone=inference_limit burst=50 nodelay;
            
            proxy_pass http://torchserve_inference;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            
            # Higher timeout for this model
            proxy_read_timeout 120s;
            
            # Custom cache settings
            proxy_cache model_cache;
            proxy_cache_key "$scheme$request_method$host$request_uri$arg_text";
            proxy_cache_valid 200 10m;
        }

        # WebSocket support for streaming predictions
        location /ws/predictions/ {
            proxy_pass http://torchserve_inference;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "Upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_read_timeout 3600s;
        }

        # Error pages
        error_page 500 502 503 504 /50x.html;
        location = /50x.html {
            root /usr/share/nginx/html;
        }

        error_page 429 /429.html;
        location = /429.html {
            root /usr/share/nginx/html;
            add_header Retry-After 60 always;
        }
    }

    # Management API (internal access only)
    server {
        listen 8081;
        server_name models-mgmt.betterprompts.com;

        allow 10.0.0.0/8;
        allow 172.16.0.0/12;
        allow 127.0.0.1;
        deny all;

        location / {
            proxy_pass http://torchserve_management;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
    }
}